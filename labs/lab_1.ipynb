{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c96f31a",
   "metadata": {},
   "source": [
    "# Lab 1: Silver Fund Quant Data Module and Returns\n",
    "\n",
    "In this lab we will:\n",
    "- Explore how to pull data from the Silver Fund Quant data module.\n",
    "- Demonstrate the different properties of returns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a980b29",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "In order to have a smooth experience with this lab do the following:\n",
    "\n",
    "### 1. Log into the Fulton Super Computer.\n",
    "\n",
    "In order to log into you must have an account at [https://rc.byu.edu/](https://rc.byu.edu/) and be added to the `grp_quant` group by Brian Boyer.\n",
    "\n",
    "It can take some time to get approved so make sure to create an account and reach out to Brian promptly.\n",
    "\n",
    "### 2. Clone this repo to the desired location (I prefer to have a `Projects` folder where I keep all of my repositories).\n",
    "\n",
    "Clone the repo by running\n",
    "```bash\n",
    "git clone https://github.com/BYUSilverFund/sf-quant-labs.git\n",
    "```\n",
    "\n",
    "### 3. Install `uv` (Package Manager)\n",
    "\n",
    "We use `uv` to create and manage virtual environments.\n",
    "\n",
    "To install `uv` run\n",
    "\n",
    "```bash\n",
    "curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "```\n",
    "\n",
    "Check that `uv` is installed by running\n",
    "\n",
    "```bash\n",
    "uv --version\n",
    "```\n",
    "\n",
    "If this returns an error you might need to add uv to your path. Run:\n",
    "\n",
    "```bash\n",
    "source $HOME/.local/bin/env\n",
    "```\n",
    "\n",
    "Restart your terminal for the changes to take effect.\n",
    "\n",
    "### 4. Create a Virtual Environment\n",
    "\n",
    "The virtual environment will make it so that we have consistent package and Python versions across all devices.\n",
    "\n",
    "With `uv` it is really easy to create a virtual environment with synced dependencies.\n",
    "\n",
    "Just run\n",
    "\n",
    "```bash\n",
    "uv sync\n",
    "```\n",
    "\n",
    "Activate the environment by running\n",
    "\n",
    "``` bash\n",
    "source .venv/bin/activate\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46266d32",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "With all of the setup out of the way we will import the necessary Python packages for the lab.\n",
    "\n",
    "- `sf_quant`: Silver Fund Quant Team package that includes modules for loading data, optimizing portfolios, backtesting, and analyzing performance.\n",
    "- `datetime`: Native Python library for creating Python `date` types.\n",
    "- `polars`: Data frame library similar to Pandas but with a much cleaner API and 100x speed ups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e509698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sf_quant as sf\n",
    "import polars as pl\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7e2772",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Use the following code to pull data for our investment universe from 2024-01-01 to 2024-12-31."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2197b25",
   "metadata": {},
   "outputs": [
    {
     "ename": "ComputeError",
     "evalue": "expected at least 1 source",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mComputeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43msf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_assets_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/silver_fund/sf-quant-labs/.venv/lib/python3.12/site-packages/sf_quant/data/assets.py:174\u001b[39m, in \u001b[36mget_assets_columns\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_assets_columns\u001b[39m() -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    143\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[33;03m    Return the available columns in the assets dataset.\u001b[39;00m\n\u001b[32m    145\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    172\u001b[39m \u001b[33;03m    └──────────────────────┴─────────┘\u001b[39;00m\n\u001b[32m    173\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43massets_table\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/silver_fund/sf-quant-labs/.venv/lib/python3.12/site-packages/sf_quant/data/_tables.py:27\u001b[39m, in \u001b[36mTable.columns\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcolumns\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> pl.DataFrame:\n\u001b[32m     26\u001b[39m     pl.Config.set_tbl_rows(-\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     schema = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscan\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     df_str = \u001b[38;5;28mstr\u001b[39m(\n\u001b[32m     29\u001b[39m         pl.DataFrame(\n\u001b[32m     30\u001b[39m             {\n\u001b[32m   (...)\u001b[39m\u001b[32m     34\u001b[39m         )\n\u001b[32m     35\u001b[39m     )\n\u001b[32m     36\u001b[39m     pl.Config.set_tbl_rows(\u001b[32m10\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/silver_fund/sf-quant-labs/.venv/lib/python3.12/site-packages/polars/lazyframe/frame.py:2488\u001b[39m, in \u001b[36mLazyFrame.collect_schema\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2458\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcollect_schema\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Schema:\n\u001b[32m   2459\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2460\u001b[39m \u001b[33;03m    Resolve the schema of this LazyFrame.\u001b[39;00m\n\u001b[32m   2461\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2486\u001b[39m \u001b[33;03m    3\u001b[39;00m\n\u001b[32m   2487\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Schema(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ldf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, check_dtypes=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mComputeError\u001b[39m: expected at least 1 source"
     ]
    }
   ],
   "source": [
    "sf.data.get_assets_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df5bc083",
   "metadata": {},
   "outputs": [
    {
     "ename": "ComputeError",
     "evalue": "expected at least 1 source\n\nThis error occurred with the following context stack:\n\t[1] 'parquet scan'\n\t[2] 'filter'\n\t[3] 'filter'\n\t[4] 'join left'\n\t[5] 'join'\n\t[6] 'with_columns'\n\t[7] 'select'\n\t[8] 'with_columns'\n\t[9] 'filter'\n\t[10] 'select'\n\t[11] 'select'\n\t[12] 'with_columns'\n\t[13] 'filter'\n\t[14] 'select'\n\t[15] 'select'\n\t[16] 'sink'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mComputeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# TODO: create 2024-12-31 using the datetime library\u001b[39;00m\n\u001b[32m      6\u001b[39m columns = [\n\u001b[32m      7\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      8\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mbarrid\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# TODO: Add any other columns we will need for our analysis\u001b[39;00m\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# NOTE: You can view all available columns by running sf.data.get_assets_columns() in another cell\u001b[39;00m\n\u001b[32m     11\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m df = \u001b[43msf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_assets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43min_universe\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m df\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/silver_fund/sf-quant-labs/.venv/lib/python3.12/site-packages/sf_quant/data/assets.py:65\u001b[39m, in \u001b[36mload_assets\u001b[39m\u001b[34m(start, end, in_universe, columns)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[33;03mLoad a Polars DataFrame of assets data between two dates.\u001b[39;00m\n\u001b[32m     13\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     58\u001b[39m \u001b[33;03m└────────────┴─────────┴───────┘\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m in_universe:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m     62\u001b[39m         \u001b[43min_universe_assets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_between\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m        \u001b[49m\u001b[43m.\u001b[49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbarrid\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m        \u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[43m        \u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m     )\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m     69\u001b[39m         assets_table.scan()\n\u001b[32m     70\u001b[39m         .filter(pl.col(\u001b[33m\"\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m\"\u001b[39m).is_between(start, end))\n\u001b[32m   (...)\u001b[39m\u001b[32m     73\u001b[39m         .collect()\n\u001b[32m     74\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/silver_fund/sf-quant-labs/.venv/lib/python3.12/site-packages/polars/_utils/deprecation.py:97\u001b[39m, in \u001b[36mdeprecate_streaming_parameter.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     93\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33min-memory\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[33m\"\u001b[39m\u001b[33mstreaming\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/silver_fund/sf-quant-labs/.venv/lib/python3.12/site-packages/polars/lazyframe/opt_flags.py:330\u001b[39m, in \u001b[36mforward_old_opt_flags.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m         optflags = cb(optflags, kwargs.pop(key))  \u001b[38;5;66;03m# type: ignore[no-untyped-call,unused-ignore]\u001b[39;00m\n\u001b[32m    329\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33moptimizations\u001b[39m\u001b[33m\"\u001b[39m] = optflags\n\u001b[32m--> \u001b[39m\u001b[32m330\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/silver_fund/sf-quant-labs/.venv/lib/python3.12/site-packages/polars/lazyframe/frame.py:2335\u001b[39m, in \u001b[36mLazyFrame.collect\u001b[39m\u001b[34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, engine, background, optimizations, **_kwargs)\u001b[39m\n\u001b[32m   2333\u001b[39m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[32m   2334\u001b[39m callback = _kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mpost_opt_callback\u001b[39m\u001b[33m\"\u001b[39m, callback)\n\u001b[32m-> \u001b[39m\u001b[32m2335\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mComputeError\u001b[39m: expected at least 1 source\n\nThis error occurred with the following context stack:\n\t[1] 'parquet scan'\n\t[2] 'filter'\n\t[3] 'filter'\n\t[4] 'join left'\n\t[5] 'join'\n\t[6] 'with_columns'\n\t[7] 'select'\n\t[8] 'with_columns'\n\t[9] 'filter'\n\t[10] 'select'\n\t[11] 'select'\n\t[12] 'with_columns'\n\t[13] 'filter'\n\t[14] 'select'\n\t[15] 'select'\n\t[16] 'sink'\n"
     ]
    }
   ],
   "source": [
    "start = dt.date(2024, 1, 1)\n",
    "# TODO: create 2024-01-01 using the datetime library\n",
    "end = dt.date(2024, 12, 31)\n",
    "# TODO: create 2024-12-31 using the datetime library\n",
    "\n",
    "columns = [\n",
    "    'date',\n",
    "    'barrid',\n",
    "    # TODO: Add any other columns we will need for our analysis\n",
    "    # NOTE: You can view all available columns by running sf.data.get_assets_columns() in another cell\n",
    "]\n",
    "\n",
    "df = sf.data.load_assets(\n",
    "    start=start,\n",
    "    end=end,\n",
    "    in_universe=True,\n",
    "    columns=columns\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fca7cd",
   "metadata": {},
   "source": [
    "## Log returns\n",
    "\n",
    "### Instructions\n",
    "1. Compute the log returns for each asset.\n",
    "2. Compute the cummulative log returns for each asset.\n",
    "3. Run the assertion cell to make sure you're results are correct.\n",
    "\n",
    "Make sure to sort prior to computing time series metrics and use `.over()` apply the computation in groups.\n",
    "\n",
    "Log returns have the nice property of being additive. Use this to your advantage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325acff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_compute_log_returns(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute the log returns for each security and date combo.\n",
    "\n",
    "    Args:\n",
    "        df (pl.DataFrame): Data frame containing columns date, barrid, and return\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: Data frame containing columns date, barrid, return, and log_return\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Finish this function\n",
    "\n",
    "    pass\n",
    "\n",
    "df_log = task_compute_log_returns(df)\n",
    "\n",
    "df_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ca93d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_compute_cumulative_log_returns(df_log: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute the cummulative log returns for each security and date combo.\n",
    "\n",
    "    Args:\n",
    "        df_log (pl.DataFrame): Data frame containing columns date, barrid, return, and log_return\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: Data frame containing columns date, barrid, return, log_return, and cumulative_log_return\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Finish this function\n",
    "\n",
    "    pass\n",
    "\n",
    "df_cum_log = task_compute_cumulative_log_returns(df_log)\n",
    "\n",
    "df_cum_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b478070e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_cum_log['cumulative_log_return'].max() == 2.8475532093020557"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8215914b",
   "metadata": {},
   "source": [
    "## Compounded Returns\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Compute the cumulative compounded returns for each asset.\n",
    "2. Run the assertion to check that your results are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bd8e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_compute_cumulative_compounded_returns(df_cum_log: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute the cumulative compounded returns for each security.\n",
    "\n",
    "    Args:\n",
    "        df_cum_log (pl.DataFrame): Data frame containing columns date, barrid, return, log_return, and cumulative_log_return\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: Data frame containing columns date, barrid, return, log_return, cumulative_log_return, and cumulative_compouned_return\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Finish this function\n",
    "\n",
    "    pass\n",
    "\n",
    "df_cum_comp = task_compute_cumulative_compounded_returns(df_cum_log)\n",
    "\n",
    "df_cum_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbfe073",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_cum_comp['cumulative_compounded_return'].max() == 16.245533963705515"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29e5907",
   "metadata": {},
   "source": [
    "## Exponentiation\n",
    "\n",
    "Note that the max cumulative log return is different from the cumulative compounded return.\n",
    "\n",
    "Why is that?\n",
    "\n",
    "The answer is that the cumulative log return is still in log space!\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Exponentiate the cumulative log returns to put them back into the original space.\n",
    "2. Check that the exponentiated returns match the cumulative compounded returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22518ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_exponentiate_returns(df_cum_comp: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Exponentiate the cumulative log returns.\n",
    "\n",
    "    Args:\n",
    "        df_cum_comp: Data frame containing date, barrid, return, log_return, cumulative_log_return, and cumulative_compouned_return.\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: Data frame containing all previous columns plus exponentiated_returns\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Finish this function\n",
    "\n",
    "    pass\n",
    "\n",
    "df_exp = task_exponentiate_returns(df_cum_comp)\n",
    "\n",
    "df_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f01babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_exp['cumulative_compounded_return'].max() == df_exp['exponentiated_return'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e013c6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sf-quant-labs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
